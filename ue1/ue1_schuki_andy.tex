\documentclass[DIN, pagenumber=false, fontsize=11pt, parskip=half]{scrartcl}

\usepackage{ngerman}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{ amssymb }
\usepackage{pgfplots}
\usepackage{enumerate}

% for matlab code
% bw = blackwhite - optimized for print, otherwise source is colored
%\usepackage[framed,numbered,bw]{mcode}

% for other code
%\usepackage{listings}

\setlength{\parindent}{0em}

% set section in CM
\setkomafont{section}{\normalfont\bfseries\Large}

\newcommand{\mytitle}[1]{{\noindent\textbf{#1}}}
\newcommand{\sol}{\underline{Solution:} }
\usepackage{fancyhdr}

\pagestyle{fancy}
\fancyhf{}
\rhead{ Andreas Rist \\  Joshua Marben}
\lhead{University Tübingen \\Self Driving Cars WiSe 2018/19}
\fancyfoot{}
\lfoot{{ andreas.rist@student.uni-tuebingen.de}\\ { joshua.marben@student.uni-tuebingen.de}}
\rfoot{ Page \thepage}
\renewcommand{\headrulewidth}{2pt}
\renewcommand{\footrulewidth}{1pt}
\renewcommand\thesection{\underline {Task \arabic{section}:}}
%===================================
\begin{document}
\mytitle{{\huge Excercise 1} \hfill \today}
%===================================
\section{Network Design }
\begin{enumerate}[b)]
	\item[b)]The module $training.py$ contains the training loop for the network. Read and understand its
	function $train$. Why is it necessary to divide the data into batches? What is an epoch? What do
	lines $43$ to $48$ do? Please answer shortly and precisely.\\
	\sol It is helpful to divide your data into batches for two reasons.
        First there is less memory used for a training epoch of the network, since we do not have to hold all data in memory for a
        training update (only the data of one batch).
        Second the network learns faster with smaller batch sizes, since there are many incremental updates to the
        weights. By not using all the data in every iteration, we introduce a certain noise, which helps the gradient
        descent.\\
	An epoch is is one forward and one backward pass of all training data.\\
	We take the batch of our training data, calculate the prediction of the network, compare them to the target values using the crossentropy-loss-function.
        Then the loss is used to propagate the error back through the network to adapt the weights in the network. 
	\item[c)] Define the set of action-classes you want to use and complete the class-methods actions to classes
	and scores to action in $network.py$\\
	\sol The provided data of the expert imitations comes as a set of three:
	\[(steer,gas,brake)\]
	with
	\begin{align*}
		steer&\in\{-1,0,1\}\\
		gas&\in \{0,0.5\}\\
		break&\in \{0,0.8\}
	\end{align*}
	We want to use following classes:\\ 
		\{steer\_left\}\\
		\{steer\_right\}\\
		\{steer\_left\ and brake\}\\
		\{steer\_right and brake\}\\		
		\{brake\}\\
		\{gas\}\\
		\{chill\}\\
		Accelerating and steering at the same time makes no sense to us, because it would conclude in a driving a donut. 
	\item[e)] Motivate your choice regarding the number of image-channels. Can you achieve better results when
	changing the hyper-parameters? Can you explain this?\\\sol
        We use all three color-channels, since we expect the network to better interpret the important difference
        between the green grass and the grey road! Regarding the hyperparameters:
	Yes, it can be archieved. As you change the hyperparameters, you change the behaviour or the calculation of the network.
        Therefore it is possible, that you can optimize by changing them. E.g. more epochs leads to a closer adaption to
        the training data, the number of epochs can thus influence the ability to abstract a certain situation. Many
        epochs lead to a low training error, however the network can only produce correct actions for situations very
        similar to the training data. More layers increase the learning capacity, however it is difficult to find a
       good number of epochs.\\
	\item[f)] \begin{enumerate}
		\item[(I)] What is ‘good’ training data? \\\sol
		Good training data is data which contains every possible situation or situations with actions which are very close the reality.
                Therefore training-data should be versatile, contain many different situations to achieve good
                generalization.
		\item[(II)] Is there any problem with only perfect imitations?\\\sol
		Perfect imitations are bad because the network can't adapt to situations which are not in the training data.
                The network needs to learn how to behave on unexpected situations and how to correct mistakes.
	\end{enumerate}
\end{enumerate}
\section{Network Improvements}
\begin{enumerate}[a)]
	\item \textbf{Observations:} What does it do?\\\sol These enables you to encoperate informations of speed,abs,steer and gyroscope into your network. Therefore not only position of the vehicle can be considered by the network, but also any of these sensors. Therefore it is possible to make different conclusions for seemingly same situations.\\
	
	How does the performance change?
	\\\sol Curves after high speed passes now enable the car to brake first, as it would usually conclude into leaving the racetrack.	
\end{enumerate}
\end{document}
